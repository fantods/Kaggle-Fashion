{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matt\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from keras.utils.data_utils import Sequence\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, Convolution2D, GlobalAveragePooling2D, GlobalMaxPooling2D, MaxPooling2D\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "\n",
    "DATA_DIR = \"../data/\"\n",
    "NUM_CLASSES = 228"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/test/1.jpg', '../data/test/2.jpg', '../data/test/3.jpg']\n"
     ]
    }
   ],
   "source": [
    "with open(DATA_DIR + \"test.json\") as test:\n",
    "    test_json = json.load(test)\n",
    "    \n",
    "# test_urls = [obj['url'] for obj in test_json['images']]\n",
    "test_paths = [\"../data/test/{}.jpg\".format(obj['imageId']) for obj in test_json['images']]\n",
    "print(test_paths[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE_SIZE = 100\n",
    "# conv_base = applications.Xception(weights = \"imagenet\", include_top=False, input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "# for layer in conv_base.layers[:3]:\n",
    "#     layer.trainable = False\n",
    "# model = Sequential()\n",
    "# model.add(conv_base)\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(1024, activation='relu'))\n",
    "# model.add(Dropout(0.4))\n",
    "# model.add(Dense(1024, activation='relu'))\n",
    "# model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "# model.load_weights(DATA_DIR + \"model.best.100.hdf5\")\n",
    "\n",
    "# model.compile(\n",
    "#     loss = \"categorical_crossentropy\", \n",
    "#     optimizer = optimizers.SGD(lr=0.0, momentum=0.9, decay=0.0, nesterov=False),\n",
    "#     metrics=[\"accuracy\"]\n",
    "# )\n",
    "\n",
    "IMAGE_SIZE = 75\n",
    "conv_base = applications.Xception(weights = \"imagenet\", include_top=False, input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "for layer in conv_base.layers[:3]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "model.load_weights(DATA_DIR + \"model.75.hdf5\")\n",
    "\n",
    "model.compile(\n",
    "    loss = \"categorical_crossentropy\", \n",
    "    optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), \n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestBatchSequence(Sequence):\n",
    "    def __init__(self, x_set, batch_size, resize = False):\n",
    "        self.x = x_set\n",
    "        self.batch_size = batch_size\n",
    "        self.resize = resize\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        images = np.empty([len(batch_x), IMAGE_SIZE, IMAGE_SIZE, 3])\n",
    "        for i, path in enumerate(batch_x):\n",
    "            try:\n",
    "                if self.resize:\n",
    "                    img = Image.open(path)\n",
    "                    img.thumbnail((IMAGE_SIZE, IMAGE_SIZE))\n",
    "                    image = np.array(img)\n",
    "                else:\n",
    "                    image = np.array(Image.open(path))\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                output = [1]*(IMAGE_SIZE*IMAGE_SIZE*3)\n",
    "                output = np.array(output).reshape(IMAGE_SIZE,IMAGE_SIZE,3).astype('uint8')\n",
    "                image = Image.fromarray(output).convert('RGB')\n",
    "            images[i, ...] = image\n",
    "        return images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "621/621 [==============================] - ETA: 23:2 - ETA: 11:5 - ETA: 8:1 - ETA: 6: - ETA: 5: - ETA: 4: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 59s - ETA: 58 - ETA: 57 - ETA: 57 - ETA: 56 - ETA: 56 - ETA: 55 - ETA: 54 - ETA: 54 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 52 - ETA: 52 - ETA: 51 - ETA: 51 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 49 - ETA: 49 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 39 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 38 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 37s 59ms/step\n",
      "Wall time: 36.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "BATCH = 64\n",
    "STEPS = len(test_paths) // BATCH\n",
    "\n",
    "test_seq = TestBatchSequence(test_paths, BATCH, resize = True)\n",
    "# test_seq = TestBatchSequence(test_paths, BATCH, resize = False)\n",
    "\n",
    "probs = model.predict_generator(\n",
    "    test_seq,\n",
    "    steps = STEPS + 1,\n",
    "    workers = 5,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5855099e-05, 4.1505727e-03, 3.8648266e-04, 1.0924552e-03,\n",
       "       7.1759155e-04, 7.1294216e-04, 4.2944127e-03, 2.7698051e-04,\n",
       "       2.0048737e-03, 3.5813719e-04, 1.2991928e-03, 2.2910607e-04,\n",
       "       1.5680384e-03, 2.1333904e-03, 1.7441035e-03, 5.5035025e-06,\n",
       "       4.2830363e-02, 5.3071203e-03, 2.3405977e-02, 1.9155590e-02,\n",
       "       6.6758005e-04, 1.6949662e-04, 5.8537571e-05, 6.1446386e-05,\n",
       "       1.6862374e-03, 1.6095447e-03, 1.3143205e-04, 2.8503847e-03,\n",
       "       1.6214438e-04, 1.0390450e-03, 5.0106813e-04, 2.8356204e-03,\n",
       "       6.7449303e-04, 6.3253025e-04, 7.6066202e-04, 8.1022028e-03,\n",
       "       2.4137851e-03, 1.3389267e-03, 6.6413888e-04, 1.6092868e-03,\n",
       "       1.1181124e-05, 9.4155950e-04, 6.5829279e-04, 1.1095888e-02,\n",
       "       5.0145725e-04, 1.3181295e-05, 1.9138595e-03, 1.4898842e-03,\n",
       "       1.1476087e-02, 1.5895652e-04, 1.7743589e-03, 1.6969508e-03,\n",
       "       1.6870156e-02, 5.3524366e-04, 1.4709062e-03, 9.1324199e-04,\n",
       "       5.2559882e-04, 6.3228840e-04, 6.9976416e-03, 5.9387094e-04,\n",
       "       3.6734713e-03, 2.5557168e-02, 3.5903538e-03, 9.6534833e-04,\n",
       "       2.5800304e-03, 1.3903436e-01, 3.4914451e-04, 6.5879831e-05,\n",
       "       1.6762279e-03, 7.7360957e-03, 1.3543589e-03, 1.5242350e-03,\n",
       "       8.1746671e-03, 1.7305135e-03, 6.9576671e-04, 3.7980397e-05,\n",
       "       1.1117195e-03, 5.6312704e-03, 1.0687742e-02, 5.9969345e-04,\n",
       "       1.0048681e-03, 1.5526816e-03, 6.7199122e-05, 7.0877290e-06,\n",
       "       1.4559542e-04, 1.1803225e-05, 4.1210549e-03, 3.7094103e-03,\n",
       "       6.5052294e-04, 1.8807426e-04, 7.0969416e-03, 1.4588598e-03,\n",
       "       1.7000844e-03, 6.6200118e-05, 3.5327387e-03, 6.2511425e-04,\n",
       "       6.2138201e-03, 1.5543999e-02, 3.2048931e-03, 4.2165457e-03,\n",
       "       2.2136485e-03, 1.2417502e-03, 1.1100637e-03, 3.5153236e-05,\n",
       "       4.0939715e-02, 3.3095211e-02, 1.3790711e-05, 3.6558220e-05,\n",
       "       1.6934774e-03, 5.9996406e-03, 9.6467417e-04, 1.9178753e-04,\n",
       "       1.1754788e-02, 2.3276214e-03, 4.1348510e-03, 1.0580952e-02,\n",
       "       2.0002585e-03, 7.1424880e-04, 1.0356700e-04, 6.3352572e-04,\n",
       "       1.0952133e-03, 4.2857504e-03, 8.1628488e-05, 8.9223598e-05,\n",
       "       1.9129351e-04, 8.3868159e-04, 6.7569985e-04, 4.9799564e-03,\n",
       "       1.2358456e-04, 7.4497517e-04, 7.9819495e-03, 1.0887318e-03,\n",
       "       8.6543504e-03, 1.8026869e-04, 1.4950787e-03, 1.2657682e-03,\n",
       "       1.7312827e-02, 1.4260201e-02, 1.1748502e-03, 1.3697637e-03,\n",
       "       1.3454914e-03, 3.5827537e-03, 3.0551394e-03, 3.4368942e-03,\n",
       "       8.7115568e-06, 3.3667547e-04, 1.1036174e-03, 1.2961188e-02,\n",
       "       2.7377592e-04, 1.5808010e-03, 6.0972967e-03, 7.7698223e-04,\n",
       "       3.6389902e-02, 6.0330248e-03, 4.1256431e-03, 1.7213699e-05,\n",
       "       4.0294355e-05, 2.4918632e-03, 3.4327053e-03, 3.0956496e-04,\n",
       "       1.9829160e-05, 9.8693399e-06, 3.2438727e-06, 1.7480230e-02,\n",
       "       2.2299276e-03, 3.1480959e-03, 2.6409861e-03, 7.6549663e-04,\n",
       "       1.3746619e-03, 6.7624459e-03, 4.0047195e-02, 3.6429621e-05,\n",
       "       7.3366362e-05, 5.2578456e-05, 6.7650941e-03, 1.0928437e-02,\n",
       "       3.4009112e-04, 1.3349944e-03, 4.4524353e-05, 8.8923220e-03,\n",
       "       4.9380907e-03, 3.8698741e-04, 2.3894662e-03, 1.0848751e-02,\n",
       "       8.2181161e-04, 1.2186057e-02, 1.1938128e-03, 5.5302808e-04,\n",
       "       4.2047338e-03, 4.4278060e-03, 7.6138771e-05, 2.0317396e-04,\n",
       "       3.8954075e-03, 6.5970176e-05, 2.1506149e-04, 4.4251315e-04,\n",
       "       1.9601114e-04, 8.3201085e-05, 2.3378892e-04, 1.1961423e-03,\n",
       "       1.2652456e-03, 2.5905756e-04, 3.0277302e-03, 3.7619660e-03,\n",
       "       5.2010105e-03, 6.1943027e-04, 3.3847187e-05, 1.3995179e-04,\n",
       "       4.8082793e-04, 2.7659894e-03, 1.6440261e-04, 1.3263114e-03,\n",
       "       7.1723579e-04, 3.4405984e-02, 1.3644807e-05, 1.1886978e-03,\n",
       "       1.9742777e-03, 6.0456553e-03, 6.6114029e-05, 3.4278124e-03,\n",
       "       5.0608473e-05, 2.3954697e-02, 3.8044422e-05, 2.6707747e-03,\n",
       "       1.6408260e-03, 4.7501703e-03, 1.1739994e-03, 4.3192404e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prob_labels(probas):\n",
    "    label_preds = []\n",
    "    for i in range(len(probas)):\n",
    "        labels = []\n",
    "        proba = list(probas[i])\n",
    "        for i, elem in enumerate(proba):\n",
    "            if elem > 0.03:\n",
    "                labels.append(i + 1)\n",
    "        label_preds.append(labels)\n",
    "    return label_preds\n",
    "\n",
    "probas = generate_prob_labels(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17, 66, 105, 106, 153, 171, 214], [17, 66, 105, 106, 153, 171, 214], [17, 66, 105, 106, 153, 171, 214], [17, 66, 105, 106, 153, 171, 214], [17, 66, 105, 106, 153, 171, 214]]\n"
     ]
    }
   ],
   "source": [
    "print(probas[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8681905eba2647f0bc0fcbfe420c98df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39706), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"submission-new.csv\",\"w\") as f:\n",
    "    f.write(\"image_id,label_id\\n\")\n",
    "    for i, labels in tqdm(enumerate(probas), total = len(probas)):\n",
    "        output_labels = \" \".join(str(x) for x in labels)\n",
    "        f.write(\"{},{}\\n\".format(i + 1, output_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
