{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import threading\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "from keras.utils.data_utils import Sequence\n",
    "from keras.callbacks import ModelCheckpoint   \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, GlobalAveragePooling2D, GlobalMaxPooling2D, MaxPooling2D\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "DATA_DIR = \"../data/\"\n",
    "NUM_CLASSES = 228\n",
    "IMAGE_SIZE = 197"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://contestimg.wish.com/api/webimage/568e16a72dfd0133cb3f7a79-large', 'https://contestimg.wish.com/api/webimage/5452f9925f313f502bf119ff-large', 'https://contestimg.wish.com/api/webimage/540584051d2d435c5a300a82-large']\n"
     ]
    }
   ],
   "source": [
    "with open(DATA_DIR + \"test.json\") as test:\n",
    "    test_json = json.load(test)\n",
    "    \n",
    "test_urls = [obj['url'] for obj in test_json['images']]\n",
    "\n",
    "print(test_urls[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 50s 1us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 1, 1, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_3 (Glob (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 30)                61470     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 228)               7068      \n",
      "=================================================================\n",
      "Total params: 23,656,250\n",
      "Trainable params: 68,538\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "conv_base = ResNet50(\n",
    "    weights='imagenet',\n",
    "    input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "    include_top = False,\n",
    "    classes = NUM_CLASSES\n",
    ")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(GlobalMaxPooling2D())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "conv_base.trainable = False\n",
    "print(model.summary())\n",
    "\n",
    "model.load_weights(DATA_DIR + \"model.best.hdf5\")\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer='rmsprop', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestBatchSequence(Sequence):\n",
    "    def __init__(self, x_set, batch_size):\n",
    "        self.x = x_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        images = [self.url_to_image(file_name) for file_name in batch_x]\n",
    "        return np.array(images), np.zeros(IMAGE_SIZE, IMAGE_SIZE, 1)\n",
    "    \n",
    "    def url_to_image(self, url):\n",
    "        try:\n",
    "            resp = urllib.urlopen(url)\n",
    "            image = np.asarray(bytearray(resp.read()), dtype='uint8')\n",
    "            image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        except:\n",
    "            output = [1]*(IMAGE_SIZE*IMAGE_SIZE*3)\n",
    "            output = np.array(output).reshape(IMAGE_SIZE,IMAGE_SIZE,3).astype('uint8')\n",
    "            image = Image.fromarray(output).convert('RGB')\n",
    "        image = np.array(image)\n",
    "        image = resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_to_image(url):\n",
    "    try:\n",
    "        resp = urlopen(url)\n",
    "        image = np.asarray(bytearray(resp.read()), dtype='uint8')\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        output = [1]*(IMAGE_SIZE*IMAGE_SIZE*3)\n",
    "        output = np.array(output).reshape(IMAGE_SIZE,IMAGE_SIZE,3).astype('uint8')\n",
    "        image = Image.fromarray(output).convert('RGB')        \n",
    "    image = image[...,::-1]\n",
    "    image = np.array(image)\n",
    "    image = resize(image, (IMAGE_SIZE, IMAGE_SIZE))    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matt/dev/ML/kaggle-fashion/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/matt/dev/ML/kaggle-fashion/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "with open(\"submission.csv\",\"w\") as f:\n",
    "    for i, image_url in enumerate(test_urls):\n",
    "        image = url_to_image(image_url)\n",
    "        prob = model.predict_proba(image.reshape(1, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "        sorted_args = np.argsort(prob)[0][::-1][:10]\n",
    "        output_labels = \" \".join(str(x) for x in sorted_args)\n",
    "        # print(\"{}: {}\".format(i + 1, output_labels))\n",
    "        f.write(\"{}, {}\\n\".format(i + 1, output_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
