{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matt\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import threading\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "from keras.utils.data_utils import Sequence\n",
    "from keras.callbacks import ModelCheckpoint   \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, GlobalAveragePooling2D, GlobalMaxPooling2D, MaxPooling2D\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "\n",
    "DATA_DIR = \"../input/\"\n",
    "NUM_CLASSES = 228\n",
    "IMAGE_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(DATA_DIR + \"train.json\") as train, open(DATA_DIR + \"test.json\") as test, open(DATA_DIR + \"validation.json\") as validation:\n",
    "    train_json = json.load(train)\n",
    "    test_json = json.load(test)\n",
    "    validation_json = json.load(validation)\n",
    "    \n",
    "train_paths = [\"../input/train/{}.jpg\".format(obj['imageId']) for obj in train_json['images']]\n",
    "test_paths = [\"../input/test/{}.jpg\".format(obj['imageId']) for obj in test_json['images']]\n",
    "validation_paths = [\"../input/validation/{}.jpg\".format(obj['imageId']) for obj in validation_json['images']]\n",
    "\n",
    "def generate_label_array(json_obj):\n",
    "    result = []\n",
    "    for data in json_obj['annotations']:\n",
    "        temp_array = [0] * NUM_CLASSES\n",
    "        for elem in data['labelId']:\n",
    "            temp_array[int(elem) - 1] = 1\n",
    "        result.append(temp_array)\n",
    "    return np.array(result)\n",
    "\n",
    "train_labels = generate_label_array(train_json)\n",
    "validation_labels = generate_label_array(validation_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = train_paths[:1000]\n",
    "validation_paths = validation_paths[:1000]\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "validation_labels = validation_labels[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSequence(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        return np.array([\n",
    "            resize(imread(file_name), (IMAGE_SIZE, IMAGE_SIZE))\n",
    "               for file_name in batch_x]), np.array(batch_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                15390     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 228)               7068      \n",
      "=================================================================\n",
      "Total params: 14,737,146\n",
      "Trainable params: 22,458\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "conv_base = VGG16(\n",
    "    weights='imagenet',\n",
    "    input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "    include_top = False,\n",
    "    classes = NUM_CLASSES\n",
    ")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(GlobalMaxPooling2D())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "conv_base.trainable = False\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matt\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 149s 5s/step - loss: 28.0230 - acc: 0.0615 - val_loss: 36.6475 - val_acc: 0.0350\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 36.64746, saving model to model.best.hdf5\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 165s 5s/step - loss: 25.2223 - acc: 0.1321 - val_loss: 35.5426 - val_acc: 0.0410\n",
      "\n",
      "Epoch 00002: val_loss improved from 36.64746 to 35.54256, saving model to model.best.hdf5\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 184s 6s/step - loss: 24.6601 - acc: 0.1351 - val_loss: 35.2670 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00003: val_loss improved from 35.54256 to 35.26704, saving model to model.best.hdf5\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 193s 6s/step - loss: 24.3448 - acc: 0.1493 - val_loss: 35.0896 - val_acc: 0.0400\n",
      "\n",
      "Epoch 00004: val_loss improved from 35.26704 to 35.08957, saving model to model.best.hdf5\n",
      "Epoch 5/5\n",
      " 5/31 [===>..........................] - ETA: 1:20 - loss: 23.4729 - acc: 0.1437"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "BATCH = 32\n",
    "STEPS = len(train_paths) // BATCH\n",
    "VAL_STEPS = len(validation_paths) // BATCH\n",
    "\n",
    "train_gen = BatchSequence(train_paths, train_labels, BATCH)\n",
    "val_gen = BatchSequence(validation_paths, validation_labels, BATCH)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer='rmsprop', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='model.best.hdf5', \n",
    "    verbose=1,\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "history = model.fit_generator(\n",
    "    generator = train_gen,\n",
    "    validation_data = val_gen,\n",
    "    epochs = EPOCHS,\n",
    "    steps_per_epoch = STEPS,\n",
    "    callbacks = [checkpointer],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
