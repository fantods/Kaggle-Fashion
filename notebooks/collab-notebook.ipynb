{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle\n",
    "!mkdir .kaggle\n",
    "!touch .kaggle/kaggle.json \n",
    "!chmod 600 .kaggle/kaggle.json\n",
    "# add kaggle_creds to kaggle.json\n",
    "!kaggle competitions download -c imaterialist-challenge-fashion-2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip /content/.kaggle/competitions/imaterialist-challenge-fashion-2018/test.json.zip -d data/\n",
    "!unzip /content/.kaggle/competitions/imaterialist-challenge-fashion-2018/train.json.zip -d data/\n",
    "!unzip /content/.kaggle/competitions/imaterialist-challenge-fashion-2018/validation.json.zip -d data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import threading\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint   \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, GlobalAveragePooling2D, GlobalMaxPooling2D, MaxPooling2D\n",
    "\n",
    "DATA_DIR = \"data/\"\n",
    "NUM_CLASSES = 228"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR + \"train.json\") as train, open(DATA_DIR + \"test.json\") as test, open(DATA_DIR + \"validation.json\") as validation:\n",
    "    train_json = json.load(train)\n",
    "    test_json = json.load(test)\n",
    "    validation_json = json.load(validation)\n",
    "    \n",
    "\n",
    "train_urls = [obj['url'] for obj in train_json['images']]\n",
    "test_urls = [obj['url'] for obj in test_json['images']]\n",
    "validation_urls = [obj['url'] for obj in validation_json['images']]\n",
    "\n",
    "train_urls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_label_array(json_obj):\n",
    "    result = []\n",
    "    for data in json_obj['annotations']:\n",
    "        temp_array = [0] * NUM_CLASSES\n",
    "        for elem in data['labelId']:\n",
    "            temp_array[int(elem) - 1] = 1\n",
    "        result.append(temp_array)\n",
    "    return np.array(result)\n",
    "\n",
    "train_labels = generate_label_array(train_json)\n",
    "validation_labels = generate_label_array(validation_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    def __init__(self, img_array, label_array, batch_size=32, target_size=(256,256)):\n",
    "        self.img_array = img_array\n",
    "        self.label_array = label_array\n",
    "        self.batch_size = batch_size\n",
    "        self.lock = threading.Lock()\n",
    "        self.TARGET_SIZE=target_size\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def next(self):\n",
    "        return self.__next__()\n",
    "      \n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            while True:\n",
    "                X = []\n",
    "                y = []\n",
    "                for i in range(self.batch_size):\n",
    "                    # get a random number\n",
    "                    rand_img = np.random.randint(0, len(self.img_array))\n",
    "                    # get label from random number\n",
    "                    img_label = np.array(self.label_array[rand_img]).reshape(1, 228)\n",
    "                    # get image path from random number\n",
    "                    img_path = self.img_array[rand_img]\n",
    "                    # open image\n",
    "                    try:\n",
    "                        img_file = urlopen(img_path)\n",
    "                        image = Image.open(img_file)\n",
    "                    except:\n",
    "                        output = [1]*(256*256*3)\n",
    "                        output = np.array(output).reshape(256,256,3).astype('uint8')\n",
    "                        image = Image.fromarray(output).convert('RGB')\n",
    "                    # resize image\n",
    "                    image_resized = image.resize(self.TARGET_SIZE, Image.ANTIALIAS)\n",
    "                    # set image to thumbnail (proper scaling)\n",
    "                    image_resized.thumbnail(self.TARGET_SIZE, Image.ANTIALIAS)\n",
    "                    # cast image as np.array\n",
    "                    X_batch = np.asarray(image_resized).reshape(1, 256, 256, 3)\n",
    "                    # with proper datatype\n",
    "                    X_batch = X_batch / 255.0\n",
    "                    X.append(X_batch)\n",
    "                    y.append(img_label)\n",
    "                return np.array(X).reshape(self.batch_size, 256, 256, 3), np.array(y).reshape(self.batch_size, 228)           \n",
    "\n",
    "train_gen = BatchGenerator(train_urls, train_labels)\n",
    "val_gen = BatchGenerator(validation_urls, validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=30, kernel_size=3, input_shape=(256, 256, 3)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(GlobalMaxPooling2D())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(228, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "STEPS = 250\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='model.best.hdf5', \n",
    "    verbose=1,\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "model.fit_generator(\n",
    "    train_gen, \n",
    "    epochs = EPOCHS,\n",
    "    steps_per_epoch = STEPS,\n",
    "    callbacks = [checkpointer],\n",
    "    validation_data = val_gen,\n",
    "    validation_steps = 1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
