{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle\n",
    "!mkdir .kaggle\n",
    "!touch .kaggle/kaggle.json \n",
    "!chmod 600 .kaggle/kaggle.json\n",
    "# add kaggle_creds to kaggle.json\n",
    "!kaggle competitions download -c imaterialist-challenge-fashion-2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip /content/.kaggle/competitions/imaterialist-challenge-fashion-2018/test.json.zip -d data/\n",
    "!unzip /content/.kaggle/competitions/imaterialist-challenge-fashion-2018/train.json.zip -d data/\n",
    "!unzip /content/.kaggle/competitions/imaterialist-challenge-fashion-2018/validation.json.zip -d data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matt/dev/ML/kaggle-fashion/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import threading\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint   \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, GlobalAveragePooling2D, GlobalMaxPooling2D, MaxPooling2D\n",
    "\n",
    "DATA_DIR = \"data/\"\n",
    "NUM_CLASSES = 228"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-946a2788ff2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"train.json\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"test.json\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"validation.json\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtest_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/train.json'"
     ]
    }
   ],
   "source": [
    "with open(DATA_DIR + \"train.json\") as train, open(DATA_DIR + \"test.json\") as test, open(DATA_DIR + \"validation.json\") as validation:\n",
    "    train_json = json.load(train)\n",
    "    test_json = json.load(test)\n",
    "    validation_json = json.load(validation)\n",
    "    \n",
    "\n",
    "train_urls = [obj['url'] for obj in train_json['images']]\n",
    "test_urls = [obj['url'] for obj in test_json['images']]\n",
    "validation_urls = [obj['url'] for obj in validation_json['images']]\n",
    "\n",
    "train_urls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_label_array(json_obj):\n",
    "    result = []\n",
    "    for data in json_obj['annotations']:\n",
    "        temp_array = [0] * NUM_CLASSES\n",
    "        for elem in data['labelId']:\n",
    "            temp_array[int(elem) - 1] = 1\n",
    "        result.append(temp_array)\n",
    "    return np.array(result)\n",
    "\n",
    "train_labels = generate_label_array(train_json)\n",
    "validation_labels = generate_label_array(validation_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SIZE=(256,256)\n",
    "\n",
    "rand_img = np.random.randint(0, len(train_urls))\n",
    "img_label = np.array(train_labels[rand_img]).reshape(1, 228)\n",
    "img_path = train_urls[rand_img]\n",
    "img_file = urlopen(img_path)\n",
    "image = Image.open(img_file)\n",
    "image_resized = image.resize(TARGET_SIZE, Image.ANTIALIAS)\n",
    "image_resized.thumbnail(TARGET_SIZE, Image.ANTIALIAS)\n",
    "plt.imshow(np.asarray(image_resized))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    def __init__(self, img_array, label_array, batch_size=32, target_size=(256,256)):\n",
    "        self.img_array = img_array\n",
    "        self.label_array = label_array\n",
    "        self.batch_size = batch_size\n",
    "        self.lock = threading.Lock()\n",
    "        self.TARGET_SIZE=target_size\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def next(self):\n",
    "        return self.__next__()\n",
    "      \n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            while True:\n",
    "                X = []\n",
    "                y = []\n",
    "                for i in range(self.batch_size):\n",
    "                    # get a random number\n",
    "                    rand_img = np.random.randint(0, len(self.img_array))\n",
    "                    # get label from random number\n",
    "                    img_label = np.array(self.label_array[rand_img]).reshape(1, 228)\n",
    "                    # get image path from random number\n",
    "                    img_path = self.img_array[rand_img]\n",
    "                    # open image\n",
    "                    try:\n",
    "                        img_file = urlopen(img_path)\n",
    "                        image = Image.open(img_file)\n",
    "                    except:\n",
    "                        output = [1]*(256*256*3)\n",
    "                        output = np.array(output).reshape(256,256,3).astype('uint8')\n",
    "                        image = Image.fromarray(output).convert('RGB')\n",
    "                    # resize image\n",
    "                    image_resized = image.resize(self.TARGET_SIZE, Image.ANTIALIAS)\n",
    "                    # set image to thumbnail (proper scaling)\n",
    "                    image_resized.thumbnail(self.TARGET_SIZE, Image.ANTIALIAS)\n",
    "                    # cast image as np.array\n",
    "                    X_batch = np.asarray(image_resized).reshape(1, 256, 256, 3)\n",
    "                    # with proper datatype\n",
    "                    X_batch = X_batch / 255.0\n",
    "                    X.append(X_batch)\n",
    "                    y.append(img_label)\n",
    "                return np.array(X).reshape(self.batch_size, 256, 256, 3), np.array(y).reshape(self.batch_size, 228)           \n",
    "\n",
    "train_gen = BatchGenerator(train_urls, train_labels)\n",
    "val_gen = BatchGenerator(validation_urls, validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=30, kernel_size=3, input_shape=(256, 256, 3)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(GlobalMaxPooling2D())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(228, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "STEPS = 250\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='model.best.hdf5', \n",
    "    verbose=1,\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "model.fit_generator(\n",
    "    train_gen, \n",
    "    epochs = EPOCHS,\n",
    "    steps_per_epoch = STEPS,\n",
    "    callbacks = [checkpointer],\n",
    "    validation_data = val_gen,\n",
    "    validation_steps = 1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
